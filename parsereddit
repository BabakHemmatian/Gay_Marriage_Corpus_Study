#!/python27
from __future__ import print_function
from json import JSONDecoder    # imports the code to parse json
import bz2                      # imports the code to open bz2-compressed files
import os
import string
import HTMLParser
import re
import nltk
nltk.download('wordnet')
nltk.download('stopwords')
# preprocessing function
stop = set(nltk.corpus.stopwords.words('english'))
stop = [word.encode('ascii') for word in stop]
exclude = set(string.punctuation)
lemma = nltk.stem.WordNetLemmatizer()
def clean(text):
    stop_free = " ".join([i for i in text.lower().split() if i not in stop])
    punc_free = ''.join(ch for ch in stop_free if ch not in exclude)
    normalized = " ".join(lemma.lemmatize(word) for word in punc_free.split())
    return normalized
# This is the json parser
decoder = JSONDecoder(encoding='utf-8')
path = "C:/Reddit_Comments"
# choose the comments that are related to gay marriage (the syns taken from Wordnet)
GAYMAR = re.compile("(gay|homosexual|homophile|fag|faggot|fagot|queer|homo|fairy|nance|pansy|queen).*(marry|marri)", re.IGNORECASE)
for filename in os.listdir(path):
    if os.path.splitext(filename)[1] == '.bz2':
# open the file as a text file (rt="read text"), in utf8 encoding
        fin = bz2.BZ2File(filename,'r')
        output_filename = "%s_prep" % (os.path.splitext(filename)[0])
        fout = open(output_filename,'a+')#bz2.BZ2File(argv[2],'w')
    # every line is a comment
        #
        # parse the json, and turn it to regular text
        #
        for line in fin:
            comment = decoder.decode(line)
            body = HTMLParser.HTMLParser().unescape(comment["body"])
            if len(GAYMAR.findall(body)) > 0:
            # preprocess
                body = clean(body)
                body = body.encode('utf-8')
            # get rid of line breaks, and print
                print(" ".join(body.split()), sep="\t",end="\n", file=fout)
        fout.close()
print(stop)
